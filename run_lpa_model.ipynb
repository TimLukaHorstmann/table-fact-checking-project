{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution of different models against the tabfact dataset:\n",
    "\n",
    "https://github.com/huggingface/transformers/tree/main/examples/research_projects/tapex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution of the LPA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/luka512/Desktop/GitHubProjects/table-fact-checking/original_repo\n"
     ]
    }
   ],
   "source": [
    "%cd original_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/luka512/Desktop/GitHubProjects/table-fact-checking/original_repo\n",
      "--2024-12-26 10:47:25--  https://tablefact.s3-us-west-2.amazonaws.com/preprocessed_data_program.zip\n",
      "Resolving tablefact.s3-us-west-2.amazonaws.com (tablefact.s3-us-west-2.amazonaws.com)... 52.218.178.242, 52.218.233.161, 52.218.235.65, ...\n",
      "Connecting to tablefact.s3-us-west-2.amazonaws.com (tablefact.s3-us-west-2.amazonaws.com)|52.218.178.242|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 51143973 (49M) [application/zip]\n",
      "Saving to: ‘preprocessed_data_program.zip’\n",
      "\n",
      "preprocessed_data_p 100%[===================>]  48.77M  1.79MB/s    in 47s     \n",
      "\n",
      "2024-12-26 10:48:13 (1.04 MB/s) - ‘preprocessed_data_program.zip’ saved [51143973/51143973]\n",
      "\n",
      "Archive:  preprocessed_data_program.zip\n",
      "  inflating: preprocessed_data_program/simple_test.tsv  \n",
      "  inflating: preprocessed_data_program/train.tsv  \n",
      "  inflating: preprocessed_data_program/preprocessed.json  \n",
      "  inflating: preprocessed_data_program/complex_test.tsv  \n",
      "  inflating: preprocessed_data_program/small_test.tsv  \n",
      "  inflating: preprocessed_data_program/dev.tsv  \n",
      "  inflating: preprocessed_data_program/.history  \n",
      "  inflating: preprocessed_data_program/test.tsv  \n",
      "  inflating: preprocessed_data_program/vocab.json  \n",
      "  inflating: preprocessed_data_program/all_programs.json  \n"
     ]
    }
   ],
   "source": [
    "!sh get_data.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/luka512/Desktop/GitHubProjects/table-fact-checking/original_repo/code\n"
     ]
    }
   ],
   "source": [
    "%cd code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading used 1.9109632968902588 secs\n",
      "Reloading saved model checkpoints/\n",
      "TP: 40205, FP: 22854, FN: 36443, TN: 33816. precision = 0.6375774966685566: recall = 0.5245407509062108\n",
      "success = 8314, fail = 4465, accuracy = 0.650598587479569\n"
     ]
    }
   ],
   "source": [
    "!python model.py --do_test --resume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution of Table-BERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-12-26 12:27:28--  https://tablefact.s3-us-west-2.amazonaws.com/snapshot.zip\n",
      "Resolving tablefact.s3-us-west-2.amazonaws.com (tablefact.s3-us-west-2.amazonaws.com)... 52.92.202.106, 3.5.80.209, 52.218.232.121, ...\n",
      "Connecting to tablefact.s3-us-west-2.amazonaws.com (tablefact.s3-us-west-2.amazonaws.com)|52.92.202.106|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 661834130 (631M) [application/zip]\n",
      "Saving to: ‘snapshot.zip’\n",
      "\n",
      "snapshot.zip        100%[===================>] 631.17M  7.82MB/s    in 6m 0s   \n",
      "\n",
      "2024-12-26 12:33:29 (1.75 MB/s) - ‘snapshot.zip’ saved [661834130/661834130]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://tablefact.s3-us-west-2.amazonaws.com/snapshot.zip\n",
    "!unzip snapshot.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'balance': False,\n",
      " 'bert_model': 'bert-base-multilingual-cased',\n",
      " 'cache_dir': '',\n",
      " 'data_dir': '../processed_datasets',\n",
      " 'do_eval': True,\n",
      " 'do_lower_case': False,\n",
      " 'do_train': False,\n",
      " 'eval_batch_size': 16,\n",
      " 'fact': 'first',\n",
      " 'fp16': False,\n",
      " 'gradient_accumulation_steps': 1,\n",
      " 'learning_rate': 5e-05,\n",
      " 'load_dir': 'outputs_fact-first_horizontal_snapshot/save_step_12500',\n",
      " 'load_step': 0,\n",
      " 'local_rank': -1,\n",
      " 'loss_scale': 0,\n",
      " 'max_seq_length': 512,\n",
      " 'no_cuda': False,\n",
      " 'num_train_epochs': 20.0,\n",
      " 'output_dir': 'outputs',\n",
      " 'period': 500,\n",
      " 'scan': 'horizontal',\n",
      " 'seed': 42,\n",
      " 'server_ip': '',\n",
      " 'server_port': '',\n",
      " 'task_name': 'QQP',\n",
      " 'test_set': 'dev',\n",
      " 'train_batch_size': 6,\n",
      " 'warmup_proportion': 0.1}\n",
      "12/26/2024 12:51:08 - INFO - __main__ -   device: mps n_gpu: 0, distributed training: False, 16-bits training: False\n",
      "12/26/2024 12:51:08 - INFO - __main__ -   Datasets are loaded from ../processed_datasets/tsv_data_horizontal\n",
      "Outputs will be saved to outputs_fact-first_horizontal\n",
      "load_step = 12500\n",
      "12/26/2024 12:51:09 - INFO - __main__ -   convert_examples_to_features ...\n",
      "12/26/2024 12:51:09 - INFO - __main__ -   Writing example 0 of 12791\n",
      "12/26/2024 12:51:17 - INFO - __main__ -   Writing example 10000 of 12791\n",
      "12/26/2024 12:51:20 - INFO - __main__ -   ***** Running evaluation *****\n",
      "12/26/2024 12:51:20 - INFO - __main__ -     Num examples = 12791\n",
      "12/26/2024 12:51:20 - INFO - __main__ -     Batch size = 16\n",
      "Evaluating: 100%|█████████████████████████████| 800/800 [06:20<00:00,  2.10it/s]\n",
      "12/26/2024 12:57:41 - INFO - __main__ -   save_dir is outputs_fact-first_horizontal_snapshot/save_step_12500\n",
      "12/26/2024 12:57:41 - INFO - __main__ -   ***** Eval results dev*****\n",
      "12/26/2024 12:57:41 - INFO - __main__ -     acc = 0.6574935501524509\n",
      "12/26/2024 12:57:41 - INFO - __main__ -     acc_and_f1 = 0.6754255739843238\n",
      "12/26/2024 12:57:41 - INFO - __main__ -     eval_loss = 0.589219210576266\n",
      "12/26/2024 12:57:41 - INFO - __main__ -     f1 = 0.6933575978161965\n",
      "12/26/2024 12:57:41 - INFO - __main__ -     global_step = 12500\n",
      "12/26/2024 12:57:41 - INFO - __main__ -     loss = None\n"
     ]
    }
   ],
   "source": [
    "!python run_BERT.py --do_eval --scan horizontal --fact first --load_dir outputs_fact-first_horizontal_snapshot/save_step_12500 --eval_batch_size 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAPEX-model\n",
    "\n",
    "https://github.com/huggingface/transformers/tree/main/examples/research_projects/tapex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/luka512/Desktop/GitHubProjects/table-fact-checking/TAPEX\n"
     ]
    }
   ],
   "source": [
    "%cd ~/Desktop/GitHubProjects/table-fact-checking/TAPEX/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/26/2024 13:50:45 - WARNING - __main__ - Process rank: 0, device: mps, n_gpu: 1distributed training: True, 16-bits training: False\n",
      "Downloading data: 197MB [00:39, 4.98MB/s] \n",
      "Generating train split: 100%|███| 92283/92283 [00:02<00:00, 33431.87 examples/s]\n",
      "Generating validation split: 100%|█| 12792/12792 [00:00<00:00, 32901.46 examples\n",
      "Generating test split: 100%|████| 12779/12779 [00:00<00:00, 35716.77 examples/s]\n",
      "config.json: 100%|█████████████████████████| 1.72k/1.72k [00:00<00:00, 12.1MB/s]\n",
      "[WARNING|configuration_utils.py:246] 2024-12-26 13:51:33,854 >> You passed along `num_labels=3` with an incompatible id to label map: {'0': 'Refused', '1': 'Entailed'}. The number of labels wil be overwritten to 2.\n",
      "tokenizer_config.json: 100%|███████████████| 1.18k/1.18k [00:00<00:00, 8.48MB/s]\n",
      "vocab.json: 100%|████████████████████████████| 899k/899k [00:00<00:00, 6.20MB/s]\n",
      "merges.txt: 100%|████████████████████████████| 456k/456k [00:00<00:00, 5.25MB/s]\n",
      "special_tokens_map.json: 100%|█████████████████| 772/772 [00:00<00:00, 2.89MB/s]\n",
      "pytorch_model.bin: 100%|█████████████████████| 560M/560M [01:03<00:00, 8.82MB/s]\n",
      "Running tokenizer on dataset: 100%|█| 92283/92283 [03:38<00:00, 422.90 examples/\n",
      "Running tokenizer on dataset: 100%|█| 12792/12792 [00:30<00:00, 425.29 examples/\n",
      "Running tokenizer on dataset: 100%|█| 12779/12779 [00:29<00:00, 435.59 examples/\n",
      "/Users/luka512/Desktop/GitHubProjects/table-fact-checking/TAPEX/run_tabfact_with_tapex.py:400: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      " 11%|████▏                                 | 116/1066 [04:49<1:53:26,  7.16s/it]^C\n"
     ]
    }
   ],
   "source": [
    "# Setting environment variable\n",
    "import os\n",
    "os.environ[\"EXP_NAME\"] = \"tabfact_tapex_base_eval\"\n",
    "\n",
    "# Running the command\n",
    "!python run_tabfact_with_tapex.py \\\n",
    "  --do_eval \\\n",
    "  --model_name_or_path microsoft/tapex-base-finetuned-tabfact \\\n",
    "  --output_dir $EXP_NAME \\\n",
    "  --per_device_eval_batch_size 12 \\\n",
    "  --eval_accumulation_steps 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inf554",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
